diff --git a/cpp/configs/training/selfplay1_maxsize9.cfg b/cpp/configs/training/selfplay1_maxsize9.cfg
index 0446706b..50bc598b 100644
--- a/cpp/configs/training/selfplay1_maxsize9.cfg
+++ b/cpp/configs/training/selfplay1_maxsize9.cfg
@@ -81,7 +81,7 @@ fancyKomiVarying = true  # In non-compensated handicap and fork games, vary komi
 
 # Match-----------------------------------------------------------------------------------
 
-numGameThreads = 128
+numGameThreads = 30
 maxMovesPerGame = 1600
 
 # Rules------------------------------------------------------------------------------------
diff --git a/python/selfplay/synchronous_loop.sh b/python/selfplay/synchronous_loop.sh
index 46cfbc3d..0121ab3e 100755
--- a/python/selfplay/synchronous_loop.sh
+++ b/python/selfplay/synchronous_loop.sh
@@ -12,7 +12,7 @@ set -o pipefail
 if [[ $# -lt 5 ]]
 then
     echo "Usage: $0 NAMEPREFIX BASEDIR TRAININGNAME MODELKIND USEGATING"
-    echo "Assumes katago is already built in the 'cpp' directory of the KataGo repo and the executable is present at cpp/katago."
+    echo "Assumes katago is already built in the 'cpp' directory of the KataGo repo and the executable is present at cpp/katago.exe."
     echo "NAMEPREFIX string prefix for this training run, try to pick something globally unique. Will be displayed to users when KataGo loads the model."
     echo "BASEDIR containing selfplay data and models and related directories"
     echo "TRANINGNAME name to prefix models with, specific to this training daemon"
@@ -44,16 +44,6 @@ mkdir -p "$BASEDIR"/selfplay
 mkdir -p "$BASEDIR"/gatekeepersgf
 
 # Parameters for the training run
-# NOTE: You may want to adjust the below numbers.
-# NOTE: You probably want to edit settings in cpp/configs/training/selfplay1.cfg
-# NOTE: You probably want to edit settings in cpp/configs/training/gatekeeper1.cfg
-# Such as what board sizes and rules, you want to learn, number of visits to use, etc.
-
-# Also, the parameters below are relatively small, and probably
-# good for less powerful hardware and tighter turnaround during very early training, but if
-# you have strong hardware or are later into a run you may want to reduce the overhead by scaling
-# these numbers up and doing more games and training per cycle, exporting models less frequently, etc.
-
 NUM_GAMES_PER_CYCLE=500 # Every cycle, play this many games
 NUM_THREADS_FOR_SHUFFLING=8
 NUM_TRAIN_SAMPLES_PER_EPOCH=100000  # Training will proceed in chunks of this many rows, subject to MAX_TRAIN_PER_DATA.
@@ -66,17 +56,15 @@ TAPER_WINDOW_SCALE=50000 # Parameter setting the scale at which the shuffler wil
 SHUFFLE_KEEPROWS=600000 # Needs to be larger than MAX_TRAIN_SAMPLES_PER_CYCLE, so the shuffler samples enough rows each cycle for the training to use.
 
 # Paths to the selfplay and gatekeeper configs that contain board sizes, rules, search parameters, etc.
-# See cpp/configs/training/README.md for some notes on other selfplay configs.
-SELFPLAY_CONFIG="$GITROOTDIR"/cpp/configs/training/selfplay1.cfg
-GATING_CONFIG="$GITROOTDIR"/cpp/configs/training/gatekeeper1.cfg
+SELFPLAY_CONFIG="$GITROOTDIR"/cpp/configs/training/selfplay1_maxsize9.cfg
+GATING_CONFIG="$GITROOTDIR"/cpp/configs/training/gatekeeper1_maxsize9.cfg
 
 # Copy all the relevant scripts and configs and the katago executable to a dated directory.
-# For archival and logging purposes - you can look back and see exactly the python code on a particular date
 DATE_FOR_FILENAME=$(date "+%Y%m%d-%H%M%S")
 DATED_ARCHIVE="$BASEDIR"/scripts/dated/"$DATE_FOR_FILENAME"
 mkdir -p "$DATED_ARCHIVE"
 cp "$GITROOTDIR"/python/*.py "$GITROOTDIR"/python/selfplay/*.sh "$DATED_ARCHIVE"
-cp "$GITROOTDIR"/cpp/katago "$DATED_ARCHIVE"
+cp "$GITROOTDIR"/cpp/katago.exe "$DATED_ARCHIVE"/katago.exe  # Ensure the executable is copied
 cp "$SELFPLAY_CONFIG" "$DATED_ARCHIVE"/selfplay.cfg
 cp "$GATING_CONFIG" "$DATED_ARCHIVE"/gatekeeper.cfg
 git show --no-patch --no-color > "$DATED_ARCHIVE"/version.txt
@@ -91,15 +79,13 @@ set -x
 while true
 do
     echo "Gatekeeper"
-    time ./katago gatekeeper -rejected-models-dir "$BASEDIR"/rejectedmodels -accepted-models-dir "$BASEDIR"/models/ -sgf-output-dir "$BASEDIR"/gatekeepersgf/ -test-models-dir "$BASEDIR"/modelstobetested/ -config "$DATED_ARCHIVE"/gatekeeper.cfg -quit-if-no-nets-to-test | tee -a "$BASEDIR"/gatekeepersgf/stdout.txt
+    time "C:\Users\chang\Downloads\katago-v1.15.1-opencl-windows-x64\katago.exe" gatekeeper -rejected-models-dir "$BASEDIR"/rejectedmodels -accepted-models-dir "$BASEDIR"/models/ -sgf-output-dir "$BASEDIR"/gatekeepersgf/ -test-models-dir "$BASEDIR"/modelstobetested/ -config "$DATED_ARCHIVE"/gatekeeper.cfg -quit-if-no-nets-to-test | tee -a "$BASEDIR"/gatekeepersgf/stdout.txt
 
     echo "Selfplay"
-    time ./katago selfplay -max-games-total "$NUM_GAMES_PER_CYCLE" -output-dir "$BASEDIR"/selfplay -models-dir "$BASEDIR"/models -config "$DATED_ARCHIVE"/selfplay.cfg | tee -a "$BASEDIR"/selfplay/stdout.txt
+    time "C:\Users\chang\Downloads\katago-v1.15.1-opencl-windows-x64\katago.exe" selfplay -max-games-total "$NUM_GAMES_PER_CYCLE" -output-dir "$BASEDIR"/selfplay -models-dir "$BASEDIR"/models -config "$DATED_ARCHIVE"/selfplay.cfg | tee -a "$BASEDIR"/selfplay/stdout.txt
 
     echo "Shuffle"
     (
-        # Skip validate since peeling off 5% of data is actually a bit too chunky and discrete when running at a small scale, and validation data
-        # doesn't actually add much to debugging a fast-changing RL training.
         time SKIP_VALIDATE=1 ./shuffle.sh "$BASEDIR" "$SCRATCHDIR" "$NUM_THREADS_FOR_SHUFFLING" "$BATCHSIZE" -min-rows "$SHUFFLE_MINROWS" -keep-target-rows "$SHUFFLE_KEEPROWS" -taper-window-scale "$TAPER_WINDOW_SCALE" | tee -a "$BASEDIR"/logs/outshuffle.txt
     )
 
